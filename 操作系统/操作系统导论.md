操作系统：允许程序共享内存，让程序与设备交互

虚拟化（第一个主题）：让程序共享CPU，让许多程序可以同时访问自己的指令和数据（从而共享内存），让许多程序访问设备（从而共享磁盘）。即系统拥有非常多的虚拟CPU的假象

**陷阱和陷阱处理程序**：

- 陷阱是一种异常事件，它可以由硬件、软件或用户程序触发。当一个陷阱事件发生时，CPU会暂停当前执行的指令，然后跳转到一个预定义的地址，这个地址指向操作系统内的陷阱处理程序。
- 陷阱处理程序是操作系统的一部分，用于处理不同类型的陷阱事件。在虚拟化 CPU 中，其中一个重要的陷阱是系统调用，允许用户程序请求操作系统提供的服务。通过陷阱，操作系统可以截获用户程序的请求，并在必要时执行相应的操作，如文件操作、内存分配等。

系统调用接口:将需求传达给操作系统

**状态保存和恢复**：

- 当操作系统需要切换到不同的进程时，它必须保存当前进程的状态，以便稍后能够恢复执行。这个状态通常包括程序计数器（PC）、寄存器值、内存映射等。
- 操作系统会将当前进程的状态保存到内存中的特定位置，然后加载下一个进程的状态。这确保了进程间的无缝切换，并允许多个进程共享同一个 CPU。

并发（第二个主题）：问题同时出现且必须解决

原子方式：所有指令一次性执行

持久性（第三个主题）

时间中断：时间中断是指在计算机系统中，操作系统通过周期性地中断正在执行的程序，以便处理各种系统任务和服务请求的机制。时间中断的主要目的是确保操作系统能够有效地管理计算机资源，为多个任务提供公平的时间片，并防止某个任务长时间占用处理器而导致系统无响应。

## 进程调度

**当度量指标为周转时间时：**

先进先出调度（FIFO）：一些耗时较少的潜在资源消费者可能被排在重量级的资源消费者之后

最短任务优先（SJF）：先运行最短的任务，然后是次短的任务，如此下去

最短完成时间优先（STCF）：每当新工作进入系统时，它就会确定剩余工作和新工作中， 谁的剩余时间最少，然后调度该工作。

**当度量指标为响应时间时：**

**轮转 调度**：RR 在一个时间片（time slice，有时称为调度量子，scheduling quantum）内运行一个工作，然后切换到运行队列中的下一个任务，而不是运行一个任务直 到结束。它反复执行，直到所有任务完成。因此，RR 有时被称为时间切片（time-slicing）。 请注意，时间片长度必须是时钟中断周期的倍数。因此，如果时钟中断是每 10ms 中断一次， 则时间片可以是 10ms、20ms 或 10ms 的任何其他倍数

**摊销可以减少成本**，上下文切换的成本不仅仅来自保存和恢复少量寄存器的操作系统操作。程序 运行时，它们在 CPU 高要缓存、TLB、分支预测器和其他片上硬件中建立了大量的状态。 切换到另一个工作会导致此状态被刷新，且与当前运行的作业相关的新状态被引入，这可 能导致显著的性能成本

### 调度程序结合io

通过将每个 CPU 突发作为一项工作， 调度程序确保“交互”的进程经常运行。当这些交互式作业正在执行 I/O 时，其他 CPU 密 集型作业将运行，从而更好地利用处理器。（实现重叠）。

事实上，在一个通用的操作系统中（比如我们 所关心的操作系统），操作系统通常对每个作业的**长度知之甚少**。因此，我们如何建立一个 没有这种先验知识的 SJF/STCF？更进一步，我们如何能够将已经看到的一些想法与 RR 调 度程序结合起来，以便响应时间也变得相当不没？

**构建多级反馈队列**

## 调度：多级反馈队列

解决的问题：优化周转时间、降低响应时间

**MLFQ 的两条基本规则**：

- 规则 1：如果 A 的优先级 > B 的优先级，运行 A（不运行 B）。 
- 规则 2：如果 A 的优先级 = B 的优先级，轮转运行 A 和 B。

MLFQ改变其优先级：

- 规则 3：工作进入系统时，放在最高优先级（最上层队列）。 
- 规则 4a：工作用完整个时间片后，降低其优先级（移入下一个队列）。
-  规则 4b：如果工作在其时间片以内主动释放 CPU， 则优先级不变
- （避免密集型长时间占用CPU工作饥饿问题）**规则 5**：经过一段时间 S，就将系统中所有工作重新加入最高优先级队列
- （由于S的值不好控制，我们重写规则4a和4b）**规则 4**：一旦工作用完了其在某一层中的时间配额（无论中间主动放弃了多少次 CPU），就降低其优先级（移入低一级队列）。 

## 调度：比例份额

公平份额调度程序：：调度程序的最终目标，是确保每个工作获得一定比例的 CPU 时间，而不是优化周转时间和响 应时间。

**彩票调度**：彩票数代表了进程（或用户或其他）占 有某个资源的份额。一个进程拥有的彩票数占总彩票数的百分比，就是它占有资源的份额

**彩票机制：**

彩票货币：这种方式允许拥有一组彩票的用户以他们喜欢的某种货币， 将彩票分给自己的不同工作。之后操作系统再自动将这种货币兑换为正确的全局彩票

彩票转让：通过转让，一个进程可以临时将自己 的彩票交给另一个进程。这种机制在客户端/服务端交互的场景中尤其有用

步长调度：系统中的每个工作都有自己的步长，这个值与票数值成反比

## 多处理器调度（高级）

多核处理器（multicore）将多个 CPU 核组装在一块芯片上，是这种扩散的根源。由于计算机的架构师们当时难以让单核 CPU 更 快，同时又不增加太多功耗，所以这种多核 CPU 很快就变得流行

多处理调度器与单CPU之间的区别：区别 的核心在于对硬件缓存（cache）的使用（见图 10.1），以及多处理器之间共享数据的方式

在单CPU系统中：存在多级的硬件缓存（hardware cache），一般来说会让处理器更快 地执行程序。缓存是很小但很快的存储设备，通常拥有内存中最热的数据的备份。相比之 下，内存很大且拥有所有的数据，但访问速度较慢。通过将频繁访问的数据放在缓存中， 系统似乎拥有又大又快的内存。

**多CPU系统存在缓存一致性问题**

需要用 锁来保证数据结构状态更新的原子性

**缓存亲和度**：一个进程在某个 CPU 上运行时，会在该 CPU 的缓存中维护许多状态。下次 该进程在相同 CPU 上运行时，由于缓存中的数据而执行得更快。相反，在不同的 CPU 上执 行，会由于需要重新加载数据而很慢（好在硬件保证的缓存一致性可以保证正确执行）。因 此多处理器调度应该考虑到这种缓存亲和性，并尽可能将进程保持在同一个 CPU 上。

### 单队列调度

单队列多处理器调度（SQMS）：简单地复用单处理器调度的基本架构，将所有需要调度的工作放入一个单独的队列 中。

SQMS缺点：

- 缺乏可扩展性：只能通过加锁的方式来保证操作的原子性
- 缓存亲和性：与缓存亲和的目标背道而驰。引入亲合度机制：保持一些工作的亲和度的同时，可能需要牺牲其他工作的亲和度来 实现负载均衡。

### 多队列调度

多队列多处理器调度（MQMS）：一个CPU一个队列。基本调度框架包含多个调度队列，每个队列可以使用不同的调度规则， 比如轮转或其他任何可能的算法。当一个工作进入系统后，系统会依照一些启发性规则（如 随机或选择较空的队列）将其放入某个调度队列

MQMS缺点：负载不均

**如何应对负载不均？**

最明显的答案是让工作移动，这种技术我们称为迁移。通过工作的跨 CPU 迁移，可以真正实现负载均衡。

**系统如何决定发起这样的迁移？**

一个基本的方法是采用一种技术，名为工作窃取。工作量较少的（源）队列不定期地“偷看”其他（目标）队列是不是比自己的工作多。如果目 标队列比源队列（显著地）更满，就从目标队列“窃取”一个或多个工作，实现负载均衡。但是，如果太频繁地检查其他队列，就会带来较高的 开销，可扩展性不好，而这是多队列调度最初的全部目标！相反，如果检查间隔太长，又 可能会带来严重的负载不均。

### Linux 多处理器调度

Linux社区存在3种不同的调度程序：

- O(1)调度程序：多队列，基于优先级

- 完全公平调度程序（CFS）：比例调度方法（类似之前介绍的步长调度）

- BF 调度程序（BFS）：单队列，比例调度，但采用了更复杂的方案，称为 最早最合适虚拟截止时间优先算法

  

## 抽象：地址空间

早期系统没有多少抽象

![Alt text](%E6%97%A9%E6%9C%9F%E7%B3%BB%E7%BB%9F.png)

改进：多道程序和时分共享

### 地址空间

这个抽象叫作地址空间，是运行的程序看到 的系统中的内存。

一个进程的地址空间包含运行的程序的所有内存状态。

![Alt text](%E5%9C%B0%E5%9D%80%E7%A9%BA%E9%97%B4%E7%9A%84%E4%BE%8B%E5%AD%90.png)

![Alt text](%E5%9C%B0%E5%9D%80%E7%A9%BA%E9%97%B4%E7%9A%84%E4%BE%8B%E5%AD%902.png)

### 虚拟内存的目标

**透明**：操作系统实现虚拟内 存的方式，应该让运行的程序看不见。因此，程序不应该感知到内存被虚拟化的事实，相反，程序的行为就好像它拥有自己的私有物理内存。

**效率**：操作系统应该追求虚拟化尽可能高效 ，包括时间上（即不会使程序运行得更慢）和空间上（即不需要太多额外的内存 来支持虚拟化）。

**保护**：操作系统应确保进程受到保护， 不会受其他进程影响，操作系统本身也不会受进程影响。

补充：你看到的所有地址都不是真的（ps：打印出指针地址的c程序）。

## 插叙：内存操作 API

### 内存类型

- **栈内存**：它的申请和 释放操作是编译器来隐式管理的，所以有时也称为自动（automatic）内存。
- **堆（heap） 内存**：中所有的申请和释放操作都由程序员显式地完成。

如果为一个字符串声明空间，请使用以下习惯 用法：malloc(strlen(s) + 1)，它使用函数 strlen()获取字符串的长度，并加上 1，以便为字符 串结束符留出空间

**补充：为什么在你的进程退出时没有内存泄露？**

因为系统中实际存在两级内存管理。第一级是由操作系统执行的内存管理，操作系统在进程运行时将内存交给进程，并在进程退出（或 以其他方式结束）时将其回收。第二级管理在每个进程中，例如在调用 malloc()和 free()时，在堆内管理。 即使你没有调用 free()（并因此泄露了堆中的内存），操作系统也会在程序结束运行时，收回进程的所有 内存（包括用于代码、栈，以及相关堆的内存页）。无论地址空间中堆的状态如何，操作系统都会在进 程终止时收回所有这些页面，从而确保即使没有释放内存，也不会丢失内存。 因此，对于短时间运行的程序，泄露内存通常不会导致任何操作问题（尽管它可能被认为是不好的 形式）。

malloc()和free()不是系统调用，是库调用。因此，malloc 库管理虚拟地址空间内的空间，但是它本身 是建立在一些系统调用之上的，这些系统调用会进入操作系统，来请求本多内存或者将一 些内容释放回系统。

一个这样的系统调用叫作 brk，它被用来改变程序分断（break）的位置：堆结束的位置。 它需要一个参数（新分断的地址），从而根据新分断是大于还是小于当前分断，来增加或减 小堆的大小。另一个调用 sbrk 要求传入一个增量，但目的是类似的。

## 机制：地址转换

**如何高效、灵活地虚拟化内存？**

我们利用了一种通用技术，有时被称为基于硬件的地址转换。

利用地址转换，硬件对每次内存访问进行处理（即指令获取、数据读取或写 入），将指令中的虚拟（virtual）地址转换为数据实际存储的物理（physical）地址。因此， 在每次内存引用时，硬件都会进行地址转换，将应用程序的内存引用重定位到内存中实际 的位置。

操作系统必须管 理内存（manage memory），记录被占用和空闲的内存位置，并明智而谨慎地介入，保持对 内存使用的控制。

**基址加界限（动态重定位）**：每个 CPU 需要两个硬件寄存器：基址（base）寄存器和界限（bound）寄存 器，有时称为限制（limit）寄存器。这组基址和界限寄存器，让我们能够将地址空间放在物 理内存的任何位置，同时又能确保进程只能访问自己的地址空间。采用这种方式，在编写和编译程序时假设地址空间从零开始。但是，当程序真正执行时， 操作系统会决定其在物理内存中的实际加载地址，并将起始地址记录在基址寄存器中。该进程产生的所有内存引用，都会被处理 器通过以下方式转换为物理地址：

physical address = virtual address + base

**界限寄存器的用处在于，它确保了进程产生的所有地址都在进程的地址“界限”中**。
![Alt text](%E5%8A%A8%E6%80%81%E9%87%8D%E5%AE%9A%E4%BD%8D%E7%A1%AC%E4%BB%B6%E8%A6%81%E6%B1%82.png)

![Alt text](%E5%8A%A8%E6%80%81%E9%87%8D%E5%AE%9A%E4%BD%8D%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%A6%81%E6%B1%82.png)

## 分段

如果我们将整个地址空间放入物理内存，那么栈和堆之间的空间并 没有被进程使用，却依然占用了实际的物理内存。因此，简单的通过基址寄存器和界限寄 存器实现的虚拟内存很浪费

为了解决这个问题，分段（segmentation）的概念应运而生.在 MMU 中引入不止 一个基址和界限寄存器对，而是给地址空间内的每个逻辑段（segment）一对。一个段只是 地址空间里的一个连续定长的区域，在典型的地址空间里有 3 个逻辑不同的段：代码、栈 和堆。分段的机制使得操作系统能够将不同的段放到不同的物理内存区域，从而避免了虚 拟地址空间中的未使用部分占用物理内存。

**段错误指的是在支持分段的机器上发生了非法的内存访问。**

硬件在地址转换时使用段寄存器。它如何知道段内的偏移量，以及地址引用了哪个段？

一种常见的方式，有时称为显式（explicit）方式，就是用虚拟地址的开头几位来标识 不同的段。在隐式（implicit）方式中，硬件通过地 址产生的方式来确定段，在隐式（implicit）方式中，硬件通过地 址产生的方式来确定段。

### 栈反向增长怎么办

除了基址和界限外，硬件还需要知道段的增长方向（用 一位区分，比如 1 代表自小而大增长，0 反之）。

### 支持共享

节省内存，有时候在地址空间之间共享（share）某些 内存段是有用的。

保护位：为每个段增加了几个位，标识程序是否能够读写该段，或执行其中的代码。通过将代码段标记为只 读，同样的代码可以被多个进程共享，而不用担心破坏隔离。虽然每个进程都认为自己独占 这块内存，但操作系统秘密地共享了内存，进程不能修改这些内存，所以假象得以保持。

### 细粒度与粗粒度的分段

粗粒度：它将地址空间分成较大的、粗粒度的 块。

细粒度：允许将地址空间划分为大量 较小的段。

### 上下文切换时应该注意什么

- 各个段的寄存器中的内容必须保存和恢复。
- 管理内存的空闲空间

## 空闲空间管理

空闲列表包含一组元素，记录了堆中的哪些空间还没有分配